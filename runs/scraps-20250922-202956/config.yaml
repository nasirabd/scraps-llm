data:
  max_len: 128
  num_workers: 0
  processed_dir: data/processed
  train_batch_size: 8
  val_batch_size: 8
device: auto
model:
  d_model: 128
  dropout: 0.1
  max_len: 128
  n_heads: 4
  n_layers: 2
  tie_weights: true
optim:
  betas:
  - 0.9
  - 0.95
  epochs: 10
  grad_accum_steps: 1
  grad_clip: 1.0
  lr: 0.0003
  mixed_precision: true
  scheduler: cosine
  warmup_steps: 50
  weight_decay: 0.01
seed: 42
vocab_path: tokenizer/bpe.json
