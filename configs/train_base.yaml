# ===========================
# Scraps-LLM: base run
# ===========================

# ===========================
# Scraps-LLM: Default (Medium / 1024 Context)
# ===========================

seed: 42
device: auto

vocab_path: tokenizer/bpe.json

data:
  processed_dir: data/processed
  max_len: 256            
  train_batch_size: 512
  val_batch_size: 512
  num_workers: 2

model:
  d_model: 256
  n_layers: 8
  n_heads: 8
  max_len: 256
  dropout: 0.1
  use_rope: true
  tie_weights: true

optim:
  lr: 0.00025
  weight_decay: 0.1
  betas: [0.9, 0.95]
  grad_clip: 1.0
  epochs: 40
  warmup_steps: auto
  scheduler: cosine
  mixed_precision: true
  grad_accum_steps: 1

